{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content_type\": \"audio/mpeg\",\n",
      "    \"request_id\": \"1a9e3aac-0b23-4ed5-9643-5b345133c924\",\n",
      "    \"model_uuid\": \"d6db4f9d-0321-467c-a57c-3daca7d5b68e\",\n",
      "    \"model_name\": \"aura-asteria-en\",\n",
      "    \"characters\": 163,\n",
      "    \"transfer_encoding\": \"chunked\",\n",
      "    \"date\": \"Thu, 18 Jul 2024 19:12:56 GMT\",\n",
      "    \"filename\": \"audio.mp3\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from deepgram import DeepgramClient, SpeakOptions\n",
    "\n",
    "DEEPGRAM_API_KEY = \"Your Deepgram API KEY\"\n",
    "\n",
    "TEXT = {\n",
    "    \"text\": \"Deepgram is great for real-time conversationsâ€¦ and also, you can build apps for things like customer support, logistics, and more. What do you think of the voices?\"\n",
    "}\n",
    "FILENAME = \"audio.mp3\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        deepgram = DeepgramClient(DEEPGRAM_API_KEY)\n",
    "\n",
    "        options = SpeakOptions(\n",
    "            model=\"aura-asteria-en\",\n",
    "        )\n",
    "\n",
    "        response = deepgram.speak.v(\"1\").save(FILENAME, TEXT, options)\n",
    "        print(response.to_json(indent=4))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from deepgram import DeepgramClient, SpeakOptions\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from playsound import playsound\n",
    "import time\n",
    "\n",
    "ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"{topic}\"\"\"\n",
    "    )\n",
    "    | ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "wrapped_chain = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Faizan. I'm here to help answer any questions you have, so feel free to ask me anything! If you'd like to continue our previous conversation about neural networks, I'd be happy to provide more information.\n"
     ]
    }
   ],
   "source": [
    "r = wrapped_chain.invoke(\"what is my name?\", config={\"configurable\": {\"session_id\": \"abc123\"}})\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
